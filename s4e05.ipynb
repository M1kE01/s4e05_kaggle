{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TcMsVEEL5GyY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### First approach\n"
      ],
      "metadata": {
        "id": "TcMsVEEL5GyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdtQscWyHTdE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas.plotting import bootstrap_plot\n",
        "import plotly.express as px\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "import catboost\n",
        "import xgboost\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score,make_scorer\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\n",
        "test_data = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\n",
        "submission_data = pd.read_csv('/kaggle/input/playground-series-s4e5/sample_submission.csv')"
      ],
      "metadata": {
        "id": "pYEX40QNIa2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(submission_data.shape)\n",
        "\n",
        "data = train_data.drop('id',axis=1)"
      ],
      "metadata": {
        "id": "2SRHCZEGC6vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe().T"
      ],
      "metadata": {
        "id": "3fJCuM85C9Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(data['FloodProbability'], fill=True,gridsize=100)\n",
        "plt.title('FloodProbability')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mUh-ncTiVh0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = data.keys()"
      ],
      "metadata": {
        "id": "Zxg3bLAEVkwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=7, ncols=3, figsize=(15, 25))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    sns.violinplot(y=data[feature], ax=axes[i])\n",
        "    axes[i].set_title(feature)\n",
        "    axes[i].set_xlabel('')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oDsL_TBGVlvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=7, ncols=3, figsize=(15, 25))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    sns.boxplot(y=data[feature], ax=axes[i])\n",
        "    ax=axes[i].set_title(feature)\n",
        "    ax=axes[i].set_xlabel('')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0RLUYzpNVnId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='MonsoonIntensity', y='FloodProbability', data=data)"
      ],
      "metadata": {
        "id": "-3K5ItxYVnKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 25))\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3L7tvHuB5yw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data ,_ = train_test_split(data,test_size=0.8,random_state=42)"
      ],
      "metadata": {
        "id": "Sle7DOAP5z8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_3d(Data,x='RiverManagement',y='WetlandLoss',z='AgriculturalPractices',color='FloodProbability')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GibEMIzK51YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = len(data.columns)\n",
        "num_rows = int(np.ceil(num_cols / 3))  #ensure that there are enough rows to accommodate all columns\n",
        "\n",
        "fig, axs = plt.subplots(num_rows, 3, figsize=(20, num_rows * 5))\n",
        "for i, col in enumerate(data.columns):\n",
        "    ax = axs[i // 3, i % 3]\n",
        "    ax.hist(data[col], bins=10)\n",
        "    ax.set_title(f'Histogram of {col}')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WJIuGoD854B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['FloodProbability'], kde=True)\n",
        "plt.title('Distribution of Flood Probability')\n",
        "plt.xlabel('Flood Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, linestyle=':', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G4pHcugK54zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 10))\n",
        "sns.boxplot(data=data[features])\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Features Boxplot',fontsize = 20)\n",
        "plt.ylabel('Frequencies',fontsize = 20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KHSPIn3KeOfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset_features = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
        "                   'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality']\n",
        "\n",
        "sns.pairplot(Data[subset_features])\n",
        "plt.title('Pairplot of Selected Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Au00ObFZeQ_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data[subset_features].plot(subplots = True)\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VidPlhGbeU36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_two_plots(data):\n",
        "\n",
        "    num_features = len(data.columns)\n",
        "    num_cols = 2\n",
        "    num_rows = (num_features + 1) // num_cols\n",
        "\n",
        "    print(\"Number of features:\", num_features)\n",
        "\n",
        "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, num_rows*5))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for i, feature in enumerate(data.columns):\n",
        "        try:\n",
        "            sns.violinplot(y=data[feature], ax=axs[i*2])\n",
        "            axs[i*2].set_title('Violinplot of ' + feature)\n",
        "            sns.histplot(data=data, x=feature, kde=True, ax=axs[i*2+1])\n",
        "            axs[i*2+1].set_title('Histogram of ' + feature)\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-3Fdbnp3eY4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_values = data.mean()\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=mean_values.index, y=mean_values.values)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Mean Value of Features')\n",
        "plt.ylabel('Mean Value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lT34UbbVeb6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bootstrap_plot(data[feature], size=50, samples=50000, color='blue')"
      ],
      "metadata": {
        "id": "CfhqbyPKqibJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['fsum'] = train_data.iloc[:, :-2].sum(axis=1)\n",
        "test_data['fsum'] = test_data.iloc[:, :-1].sum(axis=1)"
      ],
      "metadata": {
        "id": "_UV2FY-Jqif5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= train_data.drop(['FloodProbability'], axis=1)\n",
        "y= train_data['FloodProbability']"
      ],
      "metadata": {
        "id": "jd_XXC3kqxc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test_data.drop('id',axis=1)"
      ],
      "metadata": {
        "id": "fKJXs2fO4byM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aXpRtgnY4kI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat = CatBoostRegressor(random_seed=12,\n",
        "                        iterations=1500,\n",
        "                        depth=7,\n",
        "                        colsample_bylevel=1.0,\n",
        "                        verbose=False)"
      ],
      "metadata": {
        "id": "LHcrpUwl4nQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "YGCEJj5n4oie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = cat.predict(test_data)"
      ],
      "metadata": {
        "id": "N671Tnji4p9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_data.keys()"
      ],
      "metadata": {
        "id": "EeSTiIrf4uRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id = submission_data['id']"
      ],
      "metadata": {
        "id": "x6Qe6OPP4vsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({'id':id, 'FloodProbability': prediction})\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "1gt8E1hR4z9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "IruBj-DJ41CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second approach"
      ],
      "metadata": {
        "id": "teKPm8Oc5Cil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon.tabular\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "o8_b7iSy5FYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee08e01b-1529-46b5-ad8f-35939a38b217"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon.tabular\n",
            "  Downloading autogluon.tabular-1.1.0-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (1.25.2)\n",
            "Requirement already satisfied: scipy<1.13,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (1.11.4)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (2.0.3)\n",
            "Collecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.tabular)\n",
            "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (3.3)\n",
            "Collecting autogluon.core==1.1.0 (from autogluon.tabular)\n",
            "  Downloading autogluon.core-1.1.0-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==1.1.0 (from autogluon.tabular)\n",
            "  Downloading autogluon.features-1.1.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m858.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.0->autogluon.tabular) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.0->autogluon.tabular) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.0->autogluon.tabular) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.0->autogluon.tabular)\n",
            "  Downloading boto3-1.34.113-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m632.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.common==1.1.0 (from autogluon.core==1.1.0->autogluon.tabular)\n",
            "  Downloading autogluon.common-1.1.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.0->autogluon.core==1.1.0->autogluon.tabular) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.0->autogluon.core==1.1.0->autogluon.tabular) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (3.5.0)\n",
            "Collecting botocore<1.35.0,>=1.34.113 (from boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.tabular)\n",
            "  Downloading botocore-1.34.113-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.tabular)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.tabular)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->autogluon.tabular) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.0->autogluon.tabular) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.0->autogluon.tabular) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.0->autogluon.tabular) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.0->autogluon.tabular) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.0->autogluon.tabular) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.0->autogluon.tabular) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.0->autogluon.tabular) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.0->autogluon.tabular) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.0->autogluon.tabular) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.0->autogluon.tabular) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.0->autogluon.tabular) (2024.2.2)\n",
            "Installing collected packages: jmespath, scikit-learn, botocore, s3transfer, boto3, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed autogluon.common-1.1.0 autogluon.core-1.1.0 autogluon.features-1.1.0 autogluon.tabular-1.1.0 boto3-1.34.113 botocore-1.34.113 jmespath-1.0.1 s3transfer-0.10.1 scikit-learn-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_url_train = '/kaggle/input/playground-series-s4e5/train.csv'\n",
        "train_data = TabularDataset(data_url_train)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "Dkt8_o3nxmKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_url_test = '/kaggle/input/playground-series-s4e5/test.csv'\n",
        "test_data = TabularDataset(data_url_test)\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "AQxzdds6xqVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_features = list(test_data.drop(columns=[\"id\"]).columns)\n",
        "initial_features"
      ],
      "metadata": {
        "id": "8P1v2FjfxtVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_vals = []\n",
        "for df in [train_data, test_data]:\n",
        "    for col in initial_features:\n",
        "        unique_vals += list(df[col].unique())\n",
        "\n",
        "unique_vals = list(set(unique_vals))\n",
        "unique_vals"
      ],
      "metadata": {
        "id": "ewZt8t18xwQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [train_data, test_data]:\n",
        "    df['fsum'] = df[initial_features].sum(axis=1)\n",
        "    df['fstd'] = df[initial_features].std(axis=1)\n",
        "    df['special1'] = df['fsum'].isin(np.arange(72, 76))\n",
        "    df['fskew'] = df[initial_features].skew(axis=1)\n",
        "    df['fkurtosis'] = df[initial_features].kurtosis(axis=1)\n",
        "\n",
        "    for i in [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]:\n",
        "        df['q_{}'.format(int(i*100))] = df[initial_features].quantile(i, axis = 1)\n",
        "\n",
        "    for v in unique_vals:\n",
        "        df['cnt_{}'.format(v)] = (df[initial_features] == v).sum(axis=1)"
      ],
      "metadata": {
        "id": "dJRmeBb7x3dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(\n",
        "     train_data.drop(columns=[\"id\"]), test_size=0.1, random_state=42, stratify=train_data.FloodProbability)"
      ],
      "metadata": {
        "id": "D9FxuzoMx6LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameter_tune_kwargs = {\n",
        "    'num_trials': 40,\n",
        "    'scheduler' : 'local',\n",
        "    'searcher'  : 'auto',\n",
        "}\n",
        "\n",
        "predictor = TabularPredictor(label = 'FloodProbability',\n",
        "                             eval_metric = 'r2',\n",
        "                             problem_type = \"regression\",\n",
        "                            )\n",
        "predictor.fit(X_train,\n",
        "              time_limit = 11*60*60,\n",
        "              hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        "              presets = 'good_quality',\n",
        "              save_space = True,\n",
        "              keep_only_best = False,\n",
        "             )"
      ],
      "metadata": {
        "id": "5auZmL5px7cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.evaluate(X_test)"
      ],
      "metadata": {
        "id": "5Gm4fr0iyB2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LB = predictor.leaderboard(X_test)\n",
        "LB"
      ],
      "metadata": {
        "id": "jzvU8Hj4yDeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = predictor.predict(test_data.drop(columns=[\"id\"]) )\n",
        "submission = pd.read_csv(\"/kaggle/input/playground-series-s4e5/sample_submission.csv\")\n",
        "submission.FloodProbability = test_preds.values\n",
        "submission.head()"
      ],
      "metadata": {
        "id": "2YmdAKStyErc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "id": "GkZYr_D4yF-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}